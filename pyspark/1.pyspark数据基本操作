
1.text格式文件读入和存储
text file is :
a,1,2
b,1,3
c,2,5

from pyspark.sql import SparkSession
builder = SparkSession.builder.appName(app_name)
builder.master(master)
spark = builder.enableHiveSupport().getOrCreate()
sc = spark.sparkContext

src_file = "hdfs://" or "file:///"
dst_file = "hdfs://" or "file:///"
df = spark.read.text(src_file)
rdd = df.rdd.map(lambda x:x[0].split(",")).map(lambda x:(x[0],int(x[1])+int(x[2])))

"""save text format"""
rdd1 = df.rdd.map(lambda x:"%s\t%d"%(x[0],x[1]))
rdd1.saveAsTextFile(save_file)

"""save parquet/csv format"""
rdd1 = rdd.toDF(["a","b"])
rdd1.write.parquet(save)   or rdd1.write.csv(save_file)


2.parquet格式文件读入和存储


